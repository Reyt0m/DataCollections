#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Example usage of Research Map Integrated Scraper

çµ±åˆã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã®ä½¿ç”¨ä¾‹
"""

from researchmap_integrated_scraper import ResearchMapIntegratedScraper
import json

def example_basic_usage():
    """
    åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹
    """
    print("=== åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹ ===")

    # Enhanced modeã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ‘ãƒ¼ã‚’åˆæœŸåŒ–
    scraper = ResearchMapIntegratedScraper(mode="enhanced")

    # ç ”ç©¶è€…ã¨ç«¶äº‰çš„ç ”ç©¶èª²é¡Œã‚’å–å¾—ï¼ˆãƒ†ã‚¹ãƒˆç”¨ã«æœ€åˆã®3äººã®ã¿ï¼‰
    results = scraper.scrape_all_researchers_and_projects(
        search_url="https://researchmap.jp/researchers?affiliation=%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE",
        max_researchers=3
    )

    print(f"å–å¾—ã—ãŸç ”ç©¶è€…æ•°: {results['processed_researchers']}")
    print(f"ç«¶äº‰çš„ç ”ç©¶èª²é¡Œæ•°: {results['total_competitive_projects']}")

    # çµæœã‚’ä¿å­˜
    scraper.save_results(results, "example_results.json")
    scraper.export_to_excel(results, "example_results.xlsx")

    print("çµæœã‚’ example_results.json ã¨ example_results.xlsx ã«ä¿å­˜ã—ã¾ã—ãŸ")

def example_different_modes():
    """
    ç•°ãªã‚‹ãƒ¢ãƒ¼ãƒ‰ã®ä½¿ç”¨ä¾‹
    """
    print("\n=== ç•°ãªã‚‹ãƒ¢ãƒ¼ãƒ‰ã®ä½¿ç”¨ä¾‹ ===")

    # Basic mode
    print("Basic mode:")
    basic_scraper = ResearchMapIntegratedScraper(mode="basic")
    basic_results = basic_scraper.scrape_all_researchers_and_projects(
        max_researchers=2
    )
    print(f"  Basic mode: ç ”ç©¶è€…{basic_results['processed_researchers']}äºº, "
          f"ç«¶äº‰çš„ç ”ç©¶èª²é¡Œ{basic_results['total_competitive_projects']}ä»¶")

    # Enhanced mode
    print("Enhanced mode:")
    enhanced_scraper = ResearchMapIntegratedScraper(mode="enhanced")
    enhanced_results = enhanced_scraper.scrape_all_researchers_and_projects(
        max_researchers=2
    )
    print(f"  Enhanced mode: ç ”ç©¶è€…{enhanced_results['processed_researchers']}äºº, "
          f"ç«¶äº‰çš„ç ”ç©¶èª²é¡Œ{enhanced_results['total_competitive_projects']}ä»¶")

    # HTML mode
    print("HTML mode:")
    html_scraper = ResearchMapIntegratedScraper(mode="html")
    html_results = html_scraper.scrape_all_researchers_and_projects(
        max_researchers=2
    )
    print(f"  HTML mode: ç ”ç©¶è€…{html_results['processed_researchers']}äºº, "
          f"ç«¶äº‰çš„ç ”ç©¶èª²é¡Œ{html_results['total_competitive_projects']}ä»¶")

def example_custom_search():
    """
    ã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢ã®ä¾‹
    """
    print("\n=== ã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢ã®ä¾‹ ===")

    scraper = ResearchMapIntegratedScraper(mode="enhanced")

    # ç•°ãªã‚‹æ¤œç´¢æ¡ä»¶ã§ã‚¹ã‚¯ãƒ¬ã‚¤ãƒ”ãƒ³ã‚°
    search_urls = [
        "https://researchmap.jp/researchers?affiliation=%E6%A0%AA%E5%BC%8F%E4%BC%9A%E7%A4%BE",
        "https://researchmap.jp/researchers?affiliation=%E5%A4%A7%E5%AD%A6",
        "https://researchmap.jp/researchers?affiliation=%E7%A0%94%E7%A9%B6%E6%A9%9F%E9%96%A2"
    ]

    for i, search_url in enumerate(search_urls, 1):
        print(f"\næ¤œç´¢ {i}: {search_url}")

        results = scraper.scrape_all_researchers_and_projects(
            search_url=search_url,
            max_researchers=1  # ãƒ†ã‚¹ãƒˆç”¨ã«1äººã®ã¿
        )

        print(f"  å–å¾—ã—ãŸç ”ç©¶è€…æ•°: {results['processed_researchers']}")
        print(f"  ç«¶äº‰çš„ç ”ç©¶èª²é¡Œæ•°: {results['total_competitive_projects']}")

def example_data_analysis():
    """
    å–å¾—ã—ãŸãƒ‡ãƒ¼ã‚¿ã®åˆ†æä¾‹
    """
    print("\n=== ãƒ‡ãƒ¼ã‚¿åˆ†æã®ä¾‹ ===")

    # Enhanced modeã§ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
    scraper = ResearchMapIntegratedScraper(mode="enhanced")
    results = scraper.scrape_all_researchers_and_projects(
        max_researchers=5
    )

    # çµ±è¨ˆæƒ…å ±ã®è¡¨ç¤º
    print(f"ç·ç ”ç©¶è€…æ•°: {results['total_researchers']}")
    print(f"å‡¦ç†æ¸ˆã¿ç ”ç©¶è€…æ•°: {results['processed_researchers']}")
    print(f"ç«¶äº‰çš„ç ”ç©¶èª²é¡Œç·æ•°: {results['total_competitive_projects']}")

    # ç ”ç©¶è€…ã”ã¨ã®è©³ç´°æƒ…å ±
    print("\nç ”ç©¶è€…è©³ç´°:")
    for i, researcher in enumerate(results['researchers'], 1):
        print(f"\n{i}. {researcher.get('name', 'Unknown')}")
        print(f"   æ‰€å±: {researcher.get('affiliation', 'N/A')}")
        print(f"   è·å: {researcher.get('position', 'N/A')}")
        print(f"   ORCID: {researcher.get('orcid_id', 'N/A')}")
        print(f"   ç ”ç©¶ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ•°: {len(researcher.get('research_keywords', []))}")
        print(f"   ç ”ç©¶åˆ†é‡æ•°: {len(researcher.get('research_areas', []))}")
        print(f"   ç«¶äº‰çš„ç ”ç©¶èª²é¡Œæ•°: {researcher.get('competitive_project_count', 0)}")

        # ç«¶äº‰çš„ç ”ç©¶èª²é¡Œã®è©³ç´°
        competitive_projects = researcher.get('competitive_projects', [])
        if competitive_projects:
            print("   ç«¶äº‰çš„ç ”ç©¶èª²é¡Œ:")
            for j, project in enumerate(competitive_projects, 1):
                print(f"     {j}. {project.get('title', 'Unknown')}")
                if project.get('funding_system'):
                    print(f"        æ”¯æ´ã‚·ã‚¹ãƒ†ãƒ : {project['funding_system']}")
                if project.get('period'):
                    print(f"        æœŸé–“: {project['period']}")

def example_error_handling():
    """
    ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ä¾‹
    """
    print("\n=== ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ä¾‹ ===")

    try:
        # ç„¡åŠ¹ãªURLã§ãƒ†ã‚¹ãƒˆ
        scraper = ResearchMapIntegratedScraper(mode="enhanced")
        results = scraper.scrape_all_researchers_and_projects(
            search_url="https://researchmap.jp/invalid-url",
            max_researchers=1
        )
        print("ç„¡åŠ¹ãªURLã§ã‚‚ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ãŒæ©Ÿèƒ½ã—ã¾ã—ãŸ")

    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼ãŒé©åˆ‡ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸ: {e}")

def main():
    """
    ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œé–¢æ•°
    """
    print("Research Map Integrated Scraper - ä½¿ç”¨ä¾‹")
    print("=" * 50)

    # å„ä¾‹ã‚’å®Ÿè¡Œ
    examples = [
        ("åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹", example_basic_usage),
        ("ç•°ãªã‚‹ãƒ¢ãƒ¼ãƒ‰ã®ä½¿ç”¨ä¾‹", example_different_modes),
        ("ã‚«ã‚¹ã‚¿ãƒ æ¤œç´¢ã®ä¾‹", example_custom_search),
        ("ãƒ‡ãƒ¼ã‚¿åˆ†æã®ä¾‹", example_data_analysis),
        ("ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®ä¾‹", example_error_handling)
    ]

    for example_name, example_func in examples:
        try:
            example_func()
            print(f"\nâœ… {example_name} ãŒæ­£å¸¸ã«å®Œäº†ã—ã¾ã—ãŸ")
        except Exception as e:
            print(f"\nâŒ {example_name} ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")

        print("-" * 50)

    print("\nğŸ‰ ã™ã¹ã¦ã®ä¾‹ãŒå®Œäº†ã—ã¾ã—ãŸï¼")
    print("ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèªã—ã¦ãã ã•ã„:")
    print("- example_results.json")
    print("- example_results.xlsx")

if __name__ == "__main__":
    main()
